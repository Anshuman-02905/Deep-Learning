{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd-qmtKxPj7m",
        "outputId": "cb84a1e0-eef0-433f-a062-3e9b68b6b5d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-21 11:28:31--  http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3127238 (3.0M) [application/x-gzip]\n",
            "Saving to: ‘review_polarity.tar.gz’\n",
            "\n",
            "review_polarity.tar 100%[===================>]   2.98M  11.5MB/s    in 0.3s    \n",
            "\n",
            "2023-03-21 11:28:33 (11.5 MB/s) - ‘review_polarity.tar.gz’ saved [3127238/3127238]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n",
        "!tar -xf review_polarity.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "from os import listdir\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA21z-WCPpSR",
        "outputId": "ff11ab61-d72e-4e8d-b39d-b267629ccdd4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_doc(filename):\n",
        "  file = open(filename,'r')\n",
        "  text = file.read()\n",
        "  file.close()\n",
        "  return text"
      ],
      "metadata": {
        "id": "-_UmAgZ47drL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_doc(doc):\n",
        "  tokens=doc.split(\" \")\n",
        "  re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "  tokens = [re_punc.sub('',w)for w in tokens]\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  stop_words= set(stopwords.words('english'))\n",
        "  tokens = [w for w in tokens if not w in stop_words]\n",
        "  tokens=[w for w in tokens if len(w)>1]\n",
        "  return tokens\n"
      ],
      "metadata": {
        "id": "w6tFRjGu7sle"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_doc_to_vocab(filename,vocab):\n",
        "  doc = load_doc(filename)\n",
        "  tokens = clean_doc(doc)\n",
        "  vocab.update(tokens)"
      ],
      "metadata": {
        "id": "EAdWLoeC9UDP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_docs(directory,vocab):\n",
        "  for filename in listdir(directory):\n",
        "    if filename.startswith('cv9'):\n",
        "      continue\n",
        "    path=directory+'/' + filename\n",
        "    add_doc_to_vocab(path,vocab)"
      ],
      "metadata": {
        "id": "-D66WV7a918u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_list(lines, filename):\n",
        "  # convert lines to a single blob of text\n",
        "  data = '\\n'.join(lines)\n",
        "  # open file\n",
        "  file = open(filename, 'w')\n",
        "  # write text\n",
        "  file.write(data)\n",
        "  # close file\n",
        "  file.close()"
      ],
      "metadata": {
        "id": "mxzV0u33BbyS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=Counter()\n",
        "process_docs(\"/content/txt_sentoken/neg\",vocab)\n",
        "process_docs(\"/content/txt_sentoken/pos\",vocab)\n",
        "print(len(vocab))\n",
        "print(vocab.most_common(50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXuVDJQX-V0d",
        "outputId": "14790ac5-3c03-4b01-a2bd-0983562f3c71"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43889\n",
            "[('film', 7978), ('movie', 4819), ('one', 4515), ('like', 3061), ('good', 2058), ('time', 2033), ('even', 1941), ('story', 1904), ('films', 1859), ('would', 1827), ('much', 1765), ('characters', 1722), ('character', 1696), ('get', 1693), ('two', 1585), ('also', 1564), ('see', 1515), ('way', 1510), ('first', 1498), ('make', 1406), ('really', 1390), ('little', 1313), ('life', 1311), ('well', 1284), ('plot', 1262), ('people', 1240), ('scene', 1239), ('could', 1235), ('bad', 1232), ('movies', 1215), ('never', 1174), ('best', 1168), ('new', 1132), ('man', 1128), ('scenes', 1116), ('doesnt', 1114), ('know', 1085), ('many', 1057), ('great', 1002), ('dont', 1000), ('love', 970), ('action', 968), ('us', 966), ('end', 944), ('go', 928), ('seems', 927), ('something', 926), ('made', 905), ('back', 905), ('work', 901)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_occurance=2\n",
        "tokens=[k for k,c in vocab.items() if c >=min_occurance]\n",
        "save_list(tokens,'vocab.txt')"
      ],
      "metadata": {
        "id": "ssEz3kDc-nnM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fwlmp4EYArSq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}